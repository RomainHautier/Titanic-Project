{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass  Sex       Age      Fare  Cabin CabinLetter\n",
      "PassengerId                                                    \n",
      "892               3    0  34.50000    7.8292    NaN         NaN\n",
      "893               3    1  47.00000    7.0000    NaN         NaN\n",
      "894               2    0  62.00000    9.6875    NaN         NaN\n",
      "895               3    0  27.00000    8.6625    NaN         NaN\n",
      "896               3    1  22.00000   12.2875    NaN         NaN\n",
      "...             ...  ...       ...       ...    ...         ...\n",
      "1305              3    0  30.27259    8.0500    NaN         NaN\n",
      "1306              1    1  39.00000  108.9000    0.0           C\n",
      "1307              3    0  38.50000    7.2500    NaN         NaN\n",
      "1308              3    0  30.27259    8.0500    NaN         NaN\n",
      "1309              3    0  30.27259   22.3583    NaN         NaN\n",
      "\n",
      "[418 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import FeatEngFun\n",
    "importlib.reload(FeatEngFun)\n",
    "from FeatEngFun import titanic_feature_eng\n",
    "from FeatEngFun import cabin_imputing_fun\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET = 'test.csv'\n",
    "\n",
    "data = pd.read_csv(DATASET, index_col = 0)\n",
    "\n",
    "data.head()\n",
    "\n",
    "if DATASET == 'test.csv':\n",
    "    if not os.path.exists('scaler.pkl') and not os.path.exists('updated_models.pkl') and not os.path.exists('enable_grid_search.pkl'):\n",
    "        user_input = input(\"One of the files required to perform the operations on the test set could not be found. Would you like to run the program using the training set to solve the errors? (Y/N): \").strip().lower()\n",
    "        if user_input == 'y':\n",
    "            DATASET = 'train.csv'\n",
    "            data = pd.read_csv(DATASET, index_col=0)\n",
    "            [dataframe, cabins] = titanic_feature_eng(data, DATASET, drop_all=True, cabin_pca=True, cabin_group_encoding=True)\n",
    "            print(dataframe)\n",
    "        else:\n",
    "            raise FileNotFoundError(\"The file 'FEng_stats_imputing' could not be found. Please run the program with the training set first.\")\n",
    "\n",
    "[dataframe, cabins] = titanic_feature_eng(data, DATASET, drop_all=True, cabin_pca=False, cabin_group_encoding=True)\n",
    "print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average fare price per cluster is:\n",
      "             mean   median\n",
      "Cabin                     \n",
      "0.0    119.488615  82.0625\n",
      "1.0     47.318413  39.0000\n",
      "0.0    0.659341\n",
      "1.0    0.340659\n",
      "Name: Cabin, dtype: float64\n",
      "Cabin                    0.0       1.0\n",
      "Fare_Interval                         \n",
      "(-0.001, 170.776]   0.586667  0.413333\n",
      "(170.776, 341.553]  1.000000  0.000000\n",
      "(341.553, 512.329]  1.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.boxenplot(x = 'Cabin', y = 'Fare', data = dataframe)\n",
    "plt.show()\n",
    "\n",
    "print('The average fare price per cluster is:')\n",
    "print(dataframe.groupby('Cabin')['Fare'].agg(['mean', 'median']))\n",
    "print(dataframe['Cabin'].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "# Assuming your data has 'Fare' and 'cluster' columns\n",
    "\n",
    "# Step 1: Define the number of intervals and calculate fare ranges\n",
    "num_intervals = 3\n",
    "fare_min, fare_max = dataframe['Fare'].min(), dataframe['Fare'].max()\n",
    "fare_bins = np.linspace(fare_min, fare_max, num_intervals + 1)  # Create interval edges\n",
    "\n",
    "# Step 2: Create a new column 'Fare_Interval' to classify fares into intervals\n",
    "dataframe['Fare_Interval'] = pd.cut(dataframe['Fare'], bins=fare_bins, include_lowest=True)\n",
    "\n",
    "# Step 3: Calculate proportions of passengers in clusters 0 and 1 by fare interval\n",
    "\"\"\" fare_cluster_proportions = pd.crosstab(\n",
    "    index=dataframe['Fare_Interval'],      # Fare intervals\n",
    "    columns=dataframe['Cabin'],          # Clusters 0 and 1\n",
    "    normalize='index'                 # Proportion by each interval\n",
    ")[[0, 1]]  # Only select clusters 0 and 1 \"\"\"\n",
    "\n",
    "fare_cluster_proportions = pd.crosstab(\n",
    "    index=dataframe['Fare_Interval'],      # Fare intervals\n",
    "    columns=dataframe['Cabin'],          # Clusters 0 and 1\n",
    "    normalize='index'                 # Proportion by each interval\n",
    ") # Only select clusters 0 and 1\n",
    "\n",
    "\n",
    "# Step 4: Display the result\n",
    "print(fare_cluster_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prices for cabins depending on the cabin floor are the following: \n",
      " Cabin\n",
      "0.0    119.488615\n",
      "1.0     47.318413\n",
      "Name: Fare, dtype: float64\n",
      "Pclass             0\n",
      "Sex                0\n",
      "Age                0\n",
      "Fare               1\n",
      "Cabin              0\n",
      "CabinLetter      327\n",
      "Fare_Interval      1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>CabinLetter</th>\n",
       "      <th>Fare_Interval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.001, 170.776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.001, 170.776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.001, 170.776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.001, 170.776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(-0.001, 170.776]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  Sex   Age     Fare  Cabin CabinLetter      Fare_Interval\n",
       "PassengerId                                                                  \n",
       "892               3    0  34.5   7.8292    1.0         NaN  (-0.001, 170.776]\n",
       "893               3    1  47.0   7.0000    1.0         NaN  (-0.001, 170.776]\n",
       "894               2    0  62.0   9.6875    1.0         NaN  (-0.001, 170.776]\n",
       "895               3    0  27.0   8.6625    1.0         NaN  (-0.001, 170.776]\n",
       "896               3    1  22.0  12.2875    1.0         NaN  (-0.001, 170.776]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Imputing the Cabins based on the cluster/cabin average fare price.\n",
    "\n",
    "dataframe = cabin_imputing_fun(dataframe)\n",
    "\n",
    "print(dataframe.isna().sum())# Splitting the datasets\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'updated_models' exists.\n",
      "Pclass    0\n",
      "Sex       0\n",
      "Age       0\n",
      "Fare      1\n",
      "Cabin     0\n",
      "dtype: int64\n",
      "Columns with NaN values: ['Fare']\n",
      "1\n",
      "mean\n",
      "condition met?\n",
      "The missing values have been imputed using mean.\n",
      "Pclass    0\n",
      "Sex       0\n",
      "Age       0\n",
      "Fare      0\n",
      "Cabin     0\n",
      "dtype: int64\n",
      "             Pclass  Sex       Age      Fare  Cabin\n",
      "PassengerId                                        \n",
      "892               3    0  0.348280 -0.486771    1.0\n",
      "893               3    1  1.306436 -0.502500    1.0\n",
      "894               2    0  2.456223 -0.451519    1.0\n",
      "895               3    0 -0.226614 -0.470963    1.0\n",
      "896               3    1 -0.609877 -0.402198    1.0\n",
      "418\n",
      "418\n",
      "418\n",
      "418\n",
      "418\n",
      "The predictions have been saved to the current directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import GridSearch\n",
    "importlib.reload(GridSearch)\n",
    "from GridSearch import gridsearch_fun\n",
    "\n",
    "standardized_columns = ['Age', 'Fare']\n",
    "\n",
    "if DATASET == 'train.csv':\n",
    "    X = dataframe.drop(['Survived', 'CabinLetter', 'Fare_Interval'], axis = 1)\n",
    "    y = dataframe['Survived']\n",
    "\n",
    "    # Dropping the columns uncessary to the models\n",
    "\n",
    "    #dataframe.drop(['CabinLetter', 'Fare_Interval'], axis = 1)\n",
    "\n",
    "    # The dataframe is now clean, ready to be split and used to\n",
    "\n",
    "    # Segmentation of the sets \"X\" et \"y\" into test (20%) and training sets (80%). \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaler.fit(X_train[standardized_columns])\n",
    "    # Saving the standard scaler to a file to be reused on the test set\n",
    "    with open('scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    X_train[standardized_columns] = scaler.transform(X_train[standardized_columns])\n",
    "    X_test[standardized_columns] = scaler.transform(X_test[standardized_columns])\n",
    "\n",
    "\n",
    "    ### Performing a gridsearch ###\n",
    "\n",
    "    enable_grid_search = gridsearch_fun(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "\n",
    "elif DATASET == 'test.csv':\n",
    "\n",
    "    # In case the test set is selected: \n",
    "\n",
    "    # 1. The potential models to use on the test set have to be saved\n",
    "    # in the updated_models file, that is after running the model grid-\n",
    "    # search.\n",
    "\n",
    "    # Check if the file exists in the current directory\n",
    "    file_path = 'updated_models'\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"The file '{file_path}' exists.\")\n",
    "    else:\n",
    "        print(f\"The file '{file_path}' does not exist.\")\n",
    "        raise FileNotFoundError(\"The file 'updated_models' could not be found.\")\n",
    "    \n",
    "    # 2. Dropping the Fare Cluster and the Cabin Letter columns.\n",
    "\n",
    "    X = dataframe.drop(['CabinLetter', 'Fare_Interval'], axis = 1)\n",
    "\n",
    "    # 3. Verifying that no missing values are present in the test set. \n",
    "    # If there are any either choose to impute them or drop the corres-\n",
    "    # ponding rows.\n",
    "\n",
    "    nan_values = X.isna().sum()\n",
    "    print(nan_values)\n",
    "    nan_columns = nan_values[nan_values > 0].index.tolist()\n",
    "    if len(nan_columns) != 0:\n",
    "        print(f\"Columns with NaN values: {nan_columns}\")\n",
    "        user_input = input(\"Would you like to impute the missing values? (Y/N): \").strip().lower()\n",
    "        if user_input == 'n':\n",
    "            X = X.dropna(axis=0)\n",
    "            print(\"The rows with missing values have been dropped.\")\n",
    "        else:\n",
    "            impute_input = input(\"What imputing technique would you like to apply (1: mean, 2: median, 3: mode)? (Y/N): \").strip().lower()\n",
    "            impute_techniques = {1: 'mean', 2: 'median', 3: 'mode'}\n",
    "\n",
    "            if int(impute_input) in impute_techniques.keys():\n",
    "                technique = impute_techniques[int(impute_input)]\n",
    "\n",
    "                if technique == 'mean':\n",
    "                    print('condition met?')\n",
    "                    X[nan_columns] = X[nan_columns].fillna(X[nan_columns].mean())\n",
    "\n",
    "                elif technique == 'median':\n",
    "                    X[nan_columns] = X[nan_columns].fillna(X[nan_columns].median())\n",
    "\n",
    "                elif technique == 'mode':\n",
    "                    X[nan_columns] = X[nan_columns].fillna(X[nan_columns].mode().iloc[0])\n",
    "                print(f\"The missing values have been imputed using {technique}.\")\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Invalid imputing technique selected.\")\n",
    "\n",
    "    # 4. Opening the save models and scaler from the training set and\n",
    "    # scaling the columns the columns that require it. \n",
    "\n",
    "    with open('updated_models', 'rb') as f:\n",
    "        updated_models = pickle.load(f)\n",
    "\n",
    "    with open('scaler.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    with open('enable_grid_search', 'rb') as f:\n",
    "        enable_grid_search = pickle.load(f)\n",
    "\n",
    "  \n",
    "    X[standardized_columns]  = scaler.transform(X[standardized_columns])\n",
    "\n",
    "\n",
    "    # 5. The models have to be used to perform predictions on the test \n",
    "    # set.\n",
    "\n",
    "    print(X.head())\n",
    "\n",
    "    for model_name in enable_grid_search:\n",
    "        opti_predictions = updated_models[model_name].predict(X)\n",
    "        print(len(opti_predictions))\n",
    "\n",
    "        prediction_filename = f'submission_{model_name}_predictions'\n",
    "\n",
    "        prediction_dataframe = pd.DataFrame({'PassengerId': X.index, 'Survived': opti_predictions})\n",
    "        prediction_dataframe.to_csv(f'{prediction_filename}.csv', index = False, header = True)\n",
    "    \n",
    "    print(\"The predictions have been saved to the current directory.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
