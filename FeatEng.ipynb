{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file stores a function destined to perform feature engineering\n",
    "# on the Titanic dataset. In this script, the general FE processes to be\n",
    "# applied to the dataset are defined and explained. \n",
    "\n",
    "# The goal is to provide clarity to the final script allowing to predict\n",
    "# whether or not a passenger of the Titanic has survived or not, whilst \n",
    "# providing multiple feature engineering paths to explore. The chosen\n",
    "# final FE process will retain that providing the best accuracy in the \n",
    "# classification exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1118791389.py, line 98)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 98\u001b[1;36m\u001b[0m\n\u001b[1;33m    elif data cabin_groups[1]:\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def titanic_feature_eng(data, drop_all, cabin_clustering):\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    # Dropping the 'Ticket', 'Name', 'Embarked', 'Parch' and 'SibSp' column.\n",
    "    if drop_all:\n",
    "        data = data.drop(['Ticket', 'Name', 'Embarked', 'Parch', 'SibSp'], axis = 1)\n",
    "\n",
    "\n",
    "    # Binary Encoding of the 'Sex' Column'\n",
    "    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "\n",
    "    # Replacing the missing values in the 'Age' column by the mean of \n",
    "    # the column.\n",
    "    data['Age'] = data['Age'].fillna(data['Age'].mean())\n",
    "\n",
    "\n",
    "    # Keeping only the first letter of the first Cabin in which the pas-\n",
    "    # senger / family member is located in. This choice is justified by\n",
    "    # the layout of cabins on the Titanic, with cabins in alphabetical \n",
    "    # order representing decks from the top to the bottom of the ship.\n",
    "    print(data['Cabin'])\n",
    "    data['Cabin'] = data['Cabin'].apply(lambda x: x.split(' ')[0][0] )\n",
    "\n",
    "    # Label encoding of the cabins.\n",
    "    original_cabins = data['Cabin']\n",
    "    data['Cabin'] = label_encoder.fit_transform(data['Cabin'])\n",
    "\n",
    "\n",
    "    # Standardising the 'Fare' and 'Age' columns.\n",
    "    standardized_columns = ['Age', 'Fare']\n",
    "    data[standardized_columns] = scaler.fit_transform(data[standardized_columns]) \n",
    "    \n",
    "    if 'Survived' not in data.columns:\n",
    "\n",
    "        print('The dataset given is the training set.')\n",
    "\n",
    "\n",
    "    ### --- PERFORMING CABIN CLUSTERING  --- ###\n",
    "\n",
    "        if cabin_clustering:\n",
    "\n",
    "            # Performing a PCA on the data set, reducing the number of \n",
    "            # features to 3. Note that only the passengers having a \n",
    "            # cabin value are considered here in order to \n",
    "            pca = PCA(n_components = 3)\n",
    "            X_pca = pca.fit_transform(data)\n",
    "            print(data.columns)\n",
    "            # Initialising the KMeans algorithm and using the elbow method to \n",
    "            # determine the optimal number of clusters.\n",
    "\n",
    "            inertia = []\n",
    "\n",
    "            for i in range(1,15):\n",
    "                KM = KMeans(init = 'k-means++', n_clusters = i, random_state = 42)\n",
    "                train_results = KM.fit(X_pca)\n",
    "                inertia.append(KM.inertia_)\n",
    "\n",
    "            # Plotting the cluster inertia vs number of clusters.\n",
    "            plt.figure()\n",
    "            sns.lineplot(x = list(range(1,15)), y = inertia, marker = 'o')\n",
    "\n",
    "\n",
    "            # After having decided upon the number of clusters to retain\n",
    "            # a second KMeans clustering is performed.\n",
    "\n",
    "            KM = KMeans(init = 'k-means++', n_clusters = 2, random_state = 42)\n",
    "            train_results = KM.fit(X_pca)\n",
    "\n",
    "            data['CabinLetter'] = data_labels\n",
    "\n",
    "            # Creating a crosstab\n",
    "            corrtable = pd.crosstab(data['cluster'], data['CabinLetter'], normalize=True)\n",
    "\n",
    "            # Now, normalize the crosstab per Cabin Letter group\n",
    "            corrtable_normalized = corrtable.div(corrtable.sum(axis=0), axis=1)\n",
    "            print(corrtable_normalized) \n",
    "\n",
    "        # When 2 clusters are created it can be seen that the groups\n",
    "        # can be created, one with cabins 'A-B-C' and the other with\n",
    "        # the rest of the cabins, making it easier to impute the \n",
    "        # missing cabins thereafter.\n",
    "        \n",
    "\n",
    "        ### --- Encoding the Cabin Groups --- ###\n",
    "\n",
    "\n",
    "    if cabin_group_encoding:\n",
    "        \n",
    "        # Defining a function to encode the cabins into 0 and 1s.\n",
    "\n",
    "        def cabin_group_encoding_fun(data):\n",
    "            cabin_groups = [['A', 'B', 'C'], ['D', 'E', 'F', 'G', 'T']]\n",
    "            \n",
    "            if data in cabin_groups[0]:\n",
    "                x = 0\n",
    "            elif data in cabin_groups[1]:\n",
    "                x = 1\n",
    "\n",
    "            return x\n",
    "\n",
    "        data['Cabin'] = data['CabinLetter'].apply(cabin_group_encoding_fun)\n",
    "\n",
    "    \n",
    "\n",
    "    ### --- DEFINING A CABIN IMPUTING METHOD --- ### MAYBE DEFINE A FUNCTION FOR THIS ALONE?\n",
    "\n",
    "    # 1. Based on the closest average fare Price\n",
    "    # 2. Using a classification model\n",
    "\n",
    "    \n",
    "            \n",
    "    return data, original_cabins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
